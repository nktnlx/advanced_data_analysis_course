{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b65af8c-c12b-4eb5-b000-8940b5575dc1",
   "metadata": {},
   "source": [
    "# Spark Practise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83abbdae-f172-4668-bf9e-4f0252e986c0",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5f38c9-bda3-4184-9434-f272793c4675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e92b81-6d84-495a-86f6-db2dd1d415c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.endpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/09 08:28:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import socket\n",
    "\n",
    "\n",
    "aws_access_key = \"your_access_key\"\n",
    "aws_secret_key = \"your_secret_key\"\n",
    "\n",
    "APACHE_MASTER_IP = socket.gethostbyname(\"apache-spark-master-0.apache-spark-headless.apache-spark.svc.cluster.local\")\n",
    "APACHE_MASTER_URL = f\"spark://{APACHE_MASTER_IP}:7077\"\n",
    "POD_IP = os.environ[\"MY_POD_IP\"]\n",
    "SPARK_APP_NAME = f\"spark-{os.environ['HOSTNAME']}\"\n",
    "JARS = \"\"\"/nfs/env/lib/python3.8/site-packages/pyspark/jars/clickhouse-native-jdbc-shaded-2.6.5.jar, \n",
    "/nfs/env/lib/python3.8/site-packages/pyspark/jars/hadoop-aws-3.3.4.jar,\n",
    "/nfs/env/lib/python3.8/site-packages/pyspark/jars/aws-java-sdk-bundle-1.12.433.jar\n",
    "\"\"\"\n",
    "\n",
    "MEM = \"512m\"\n",
    "CORES = 1\n",
    " \n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(SPARK_APP_NAME).\\\n",
    "        master(APACHE_MASTER_URL).\\\n",
    "        config(\"spark.executor.memory\", MEM).\\\n",
    "        config(\"spark.jars\", JARS).\\\n",
    "        config(\"spark.executor.cores\", CORES).\\\n",
    "        config(\"spark.driver.host\", POD_IP).\\\n",
    "        config(\"spark.hadoop.fs.s3a.access.key\", aws_access_key). \\\n",
    "        config(\"spark.hadoop.fs.s3a.secret.key\", aws_secret_key). \\\n",
    "        config(\"fs.s3a.endpoint\", \"https://storage.yandexcloud.net\").  \\\n",
    "        config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\"). \\\n",
    "        config(\"spark.hadoop.fs.s3a.path.style.access\", True). \\\n",
    "        config(\"spark.hadoop.fs.s3a.committer.name\", \"directory\"). \\\n",
    "        config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\"). \\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a46a5e-4162-4d79-a1ca-b56651d20519",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71f4eb8-48ab-4f1e-ab2c-8dee47798a80",
   "metadata": {},
   "source": [
    "Find the top 3 sellers with the highest daily goals, and then to calculate their share of the total sales made by all sellers. The share should be calculated as a percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c33dd-8714-4971-be71-042bc3071270",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f347039-5987-46ad-a280-2fb910a3f6df",
   "metadata": {},
   "source": [
    "Reading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9843c924-1143-4b1a-b40c-9b9914165df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/09 08:29:00 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sellers_df = spark.read.parquet('s3a://kc-hardda-projects/shared/sellers.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99e9422-2b60-49d5-a38a-4d481140addf",
   "metadata": {},
   "source": [
    "Checking data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e3ff57f-6896-469e-b71b-34d6672ca41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------------+\n",
      "|seller_id|seller_name|daily_target|\n",
      "+---------+-----------+------------+\n",
      "|        0|   seller_0|        2500|\n",
      "|        1|   seller_1|       16451|\n",
      "|        2|   seller_2|        2855|\n",
      "|        3|   seller_3|       19103|\n",
      "|        4|   seller_4|        8820|\n",
      "|        5|   seller_5|       14894|\n",
      "|        6|   seller_6|        7928|\n",
      "|        7|   seller_7|       17022|\n",
      "|        8|   seller_8|       19924|\n",
      "|        9|   seller_9|        6496|\n",
      "+---------+-----------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sellers_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb76bb90-65d7-4ab0-a517-7a0179ceaa2e",
   "metadata": {},
   "source": [
    "Calculating the total over daily_target column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2310885f-c948-4c78-bdac-49a694732e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "115993"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_target = sellers_df.agg({'daily_target': 'sum'}).collect()[0][0]\n",
    "total_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a0ab5-bf23-459b-9305-cd3edc35554d",
   "metadata": {},
   "source": [
    "Calculating a seller share of the total sales made by all sallers and showing the top-3 list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3734a1a1-501a-478d-84b3-32089189d1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------------+-----------------------+\n",
      "|seller_id|seller_name|daily_target|daily_target_percentage|\n",
      "+---------+-----------+------------+-----------------------+\n",
      "|        8|   seller_8|       19924|    0.17176898605950358|\n",
      "|        3|   seller_3|       19103|    0.16469097273111308|\n",
      "|        7|   seller_7|       17022|     0.1467502349279698|\n",
      "+---------+-----------+------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_df = sellers_df.withColumn('daily_target_percentage',\n",
    "                      sellers_df['daily_target'] / total_target) \\\n",
    "    .orderBy('daily_target_percentage', ascending=False).limit(3)\n",
    "\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa14849-3cda-4199-af66-a68f7354c6de",
   "metadata": {},
   "source": [
    "Saving results to a parquet file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e14310a6-8302-41c0-a47b-5f8c1ee2735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa81025c-3ecd-423a-a5df-b7cd9444c91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fin_df = result_df.toPandas()\n",
    "fin_df.to_parquet('task_1_result.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390bd58a-96ce-4d51-9a4f-22466dec4b30",
   "metadata": {},
   "source": [
    "Stopping Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f4d1b-8e78-4303-be20-d2cd6e3d1036",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
